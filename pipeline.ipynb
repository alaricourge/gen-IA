{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "07ac607a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pdfplumber\n",
    "import os\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "\n",
    "\n",
    "import google.genai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "67f7c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import List, TypedDict, Optional\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pypdf import PdfReader\n",
    "\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# api key\n",
    "load_dotenv()\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"CLAUDE_API_KEY\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0b00af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    is_legal: bool\n",
    "    codes: List[str]\n",
    "    results: dict\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    temperature=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c99004",
   "metadata": {},
   "source": [
    "### Juridique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Tu es juriste expert en droit français.\\n\"\n",
    "     \"est ce que le texte suivant relève du droit français ?\\n\"\n",
    "     \"Réponds STRICTEMENT par OUI ou NON.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "legal_chain = legal_prompt | llm | StrOutputParser()\n",
    "\n",
    "def is_french_law(state: AgentState):\n",
    "    resp = legal_chain.invoke({\"text\": state[\"input\"]}).strip().upper()\n",
    "    return {**state, \"is_legal\": resp == \"OUI\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2aff7d",
   "metadata": {},
   "source": [
    "### Code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"Retourne STRICTEMENT du JSON valide.\\n\"\n",
    "     \"tu dois extraire les noms des codes juridiques français qui pourrais etre utile dans le texte donné.\\n\"\n",
    "     \"Exemples :\\n\"\n",
    "     '[\"CodeCivil\"]\\n'\n",
    "     '[\"CodedelaRoute\"]'\n",
    "     '[\"CodeCivil\", \"CodePenal\"]\\n'\n",
    "     '[]\\n'\n",
    "     \"AUCUN texte autour.\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "def detect_codes(state: AgentState):\n",
    "    raw = code_chain.invoke({\"text\": state[\"input\"]})\n",
    "    try:\n",
    "        json_text = raw[raw.find(\"[\"):raw.rfind(\"]\")+1]\n",
    "        codes = json.loads(json_text)\n",
    "    except json.JSONDecodeError:\n",
    "        codes = []\n",
    "    return {**state, \"codes\": codes, \"results\": {}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c660fc41",
   "metadata": {},
   "source": [
    "## Recherche locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "04494b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_local_files(state: AgentState):\n",
    "    results = {}\n",
    "\n",
    "    for code in state[\"codes\"]:\n",
    "        base = f\"./code/{code}\"\n",
    "\n",
    "        if os.path.exists(base + \".xml\"):\n",
    "            results[code] = {\n",
    "                    \"type\": \"xml\",\n",
    "                    \"source\": \"local\",\n",
    "                    \"url\": base + \".xml\"\n",
    "                }\n",
    "\n",
    "        elif os.path.exists(base + \".pdf\"):\n",
    "            results[code] = {\n",
    "                    \"type\": \"pdf\",\n",
    "                    \"source\": \"local\",\n",
    "                    \"url\": base + \".pdf\"\n",
    "                }\n",
    "        else:\n",
    "            results[code] = None\n",
    "\n",
    "    return {**state, \"results\": results}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462f207",
   "metadata": {},
   "source": [
    "## Recherche online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40364cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Fonction pour normaliser la recherche\n",
    "\n",
    "\n",
    "def get_all_codes():\n",
    "    url = \"https://codes.droit.org/\"\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "\n",
    "    # Parsing du HTML avec BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Trouver tous les liens <a> dont href se termine par .xml\n",
    "    xml_links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].endswith('.xml')]\n",
    "\n",
    "    return [link.replace(\"payloads/\", \"\").replace(\".xml\", \"\") for link in xml_links]\n",
    "\n",
    "\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "def find_best_code(user_input, threshold=70):\n",
    "    codes = get_all_codes()\n",
    "\n",
    "    if not codes:\n",
    "        return None\n",
    "\n",
    "    meilleur_match = process.extractOne(user_input, codes, scorer=fuzz.ratio)\n",
    "\n",
    "    return \"https://codes.droit.org/payloads/\" + meilleur_match[0] +\".xml\"\n",
    "\n",
    "def fetch_online_xml(state: AgentState):\n",
    "    for code, result in state[\"results\"].items():\n",
    "        if result is None:\n",
    "            url = find_best_code(code)\n",
    "            r = requests.get(url)\n",
    "            if r.status_code == 200:\n",
    "                state[\"results\"][code] = {\n",
    "                    \"type\": \"xml\",\n",
    "                    \"source\": \"online\",\n",
    "                    \"url\": url\n",
    "                }\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec2d9ec",
   "metadata": {},
   "source": [
    "## CONSTRUCTION DU GRAPHE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_legal(state: AgentState):\n",
    "    return \"detect\" if state[\"is_legal\"] else END\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"is_legal\", is_french_law)\n",
    "graph.add_node(\"detect\", detect_codes)\n",
    "graph.add_node(\"local\", check_local_files)\n",
    "graph.add_node(\"online\", fetch_online_xml)\n",
    "\n",
    "graph.set_entry_point(\"is_legal\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"is_legal\",\n",
    "    route_legal,\n",
    "    {\"detect\": \"detect\", END: END}\n",
    ")\n",
    "\n",
    "graph.add_edge(\"detect\", \"local\")\n",
    "graph.add_edge(\"local\", \"online\")\n",
    "graph.add_edge(\"online\", END)\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7387c058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw codes detected: ```json\n",
      "[\"CodedelaRoute\", \"CodeCivil\"]\n",
      "```\n",
      "Parsed codes: ['CodedelaRoute', 'CodeCivil']\n",
      "{'codes': ['CodedelaRoute', 'CodeCivil'],\n",
      " 'input': \"j'ai des questions sur le code de la route et le code civil\",\n",
      " 'is_legal': True,\n",
      " 'results': {'CodeCivil': {'source': 'local',\n",
      "                           'type': 'pdf',\n",
      "                           'url': './code/CodeCivil.pdf'},\n",
      "             'CodedelaRoute': {'source': 'online',\n",
      "                               'type': 'xml',\n",
      "                               'url': 'https://codes.droit.org/payloads/Code%20de%20la%20route.xml'}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = \"j'ai des questions sur le code de la route et le code civil\"\n",
    "result = app.invoke({\n",
    "    \"input\": query\n",
    "})\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030eac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodedelaRoute {'type': 'xml', 'source': 'online', 'url': 'https://codes.droit.org/payloads/Code%20de%20la%20route.xml'}\n",
      "online\n",
      "CodeCivil {'type': 'pdf', 'source': 'local', 'url': './code/CodeCivil.pdf'}\n",
      "local\n"
     ]
    }
   ],
   "source": [
    "for i in result[\"results\"]:\n",
    "    print(result[\"results\"][i][\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050c6f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Article 1', 'content': \"Les lois et, lorsqu'ils sont publiés au Journal officiel de la République française, les actes administratifs\\nentrent en vigueur à la date qu'ils fixent ou, à défaut, le lendemain de leur publication. Toutefois, l'entrée en\\nvigueur de celles de leurs dispositions dont l'exécution nécessite des mesures d'application est reportée à la\\ndate d'entrée en vigueur de ces mesures.\\nEn cas d'urgence, entrent en vigueur dès leur publication les lois dont le décret de promulgation le prescrit et\\nles actes administratifs pour lesquels le Gouvernement l'ordonne par une disposition spéciale.\\nLes dispositions du présent article ne sont pas applicables aux actes individuels.\"}, {'title': 'Article 2', 'content': \"La loi ne dispose que pour l'avenir ; elle n'a point d'effet rétroactif.\"}, {'title': 'Article 3', 'content': \"Les lois de police et de sûreté obligent tous ceux qui habitent le territoire.\\nLes immeubles, même ceux possédés par des étrangers, sont régis par la loi française.\\nLes lois concernant l'état et la capacité des personnes régissent les Français, même résidant en pays étranger.\"}, {'title': 'Article 4', 'content': \"Le juge qui refusera de juger, sous prétexte du silence, de l'obscurité ou de l'insuffisance de la loi, pourra être\\npoursuivi comme coupable de déni de justice.\"}, {'title': 'Article 5', 'content': 'Code civil - Dernière modification le 14 septembre 2024 - Document généré le 10 février 2025\\nIl est défendu aux juges de prononcer par voie de disposition générale et réglementaire sur les causes qui leur\\nsont soumises.'}]\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdfs(file_path):\n",
    "    filename = os.path.basename(file_path)\n",
    "    path = os.path.join(file_path)\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return (filename, text)\n",
    "\n",
    "def extract_articles(code):\n",
    "    text= code[1]\n",
    "    parts = re.split(r'(Article\\s\\d+[^\\n]*)', text)\n",
    "    articles = []\n",
    "    for i in range(1, len(parts), 2):\n",
    "        title = parts[i].strip()\n",
    "        content = parts[i + 1].strip()\n",
    "        articles.append({\"code\":code[0],\"title\": title, \"content\": content,\"structure\" : None})\n",
    "    return articles\n",
    "\n",
    "\n",
    "papers = extract_text_from_pdfs(\"./code/CodeCivil.pdf\")\n",
    "\n",
    "articles = extract_articles(papers)\n",
    "# for article in articles:\n",
    "#     all_articles.append({\"filename\": papers[0], \"title\": article[\"title\"], \"content\": article[\"content\"]})\n",
    "\n",
    "print(articles[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97a89c",
   "metadata": {},
   "source": [
    "# Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141c8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting articles from code: Code pénal\n"
     ]
    }
   ],
   "source": [
    "def load_code_xml(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return ET.fromstring(response.content)\n",
    "\n",
    "def extract_articles_from_xml(root):\n",
    "    articles = []\n",
    "    # take the first line it's the title\n",
    "\n",
    "    # Structure hiérarchique actuelle\n",
    "    current_structure = {\n",
    "        0: None,  # Partie législative\n",
    "        1: None,  # Livre\n",
    "        2: None,  # Titre\n",
    "        3: None   # Chapitre\n",
    "    }\n",
    "\n",
    "    for elem in root.iter():\n",
    "        tag = elem.tag.lower()\n",
    "        if tag== \"code\":\n",
    "            code= elem.attrib.get(\"nom\")\n",
    "        # Gestion des balises <t> avec niveau\n",
    "        if tag == \"t\":\n",
    "            niveau = int(elem.attrib.get(\"niveau\", -1))\n",
    "            title = elem.attrib.get(\"title\")\n",
    "            if niveau >= 0:\n",
    "                current_structure[niveau] = title\n",
    "                # Réinitialiser les niveaux inférieurs\n",
    "                for lvl in range(niveau + 1, 4):\n",
    "                    current_structure[lvl] = None\n",
    "\n",
    "        # Gestion des articles\n",
    "        elif tag == \"article\":\n",
    "            num = elem.attrib.get(\"num\")\n",
    "            article_id = elem.attrib.get(\"id\") or elem.attrib.get(\"num\")\n",
    "            # Récupère le texte complet, en incluant <br/> comme retour à la ligne\n",
    "            texte = \"\".join(elem.itertext()).replace(\"\\n\", \" \").replace(\"<br/>\", \"\\n\").strip()\n",
    "\n",
    "            if not article_id or not texte:\n",
    "                continue\n",
    "\n",
    "            articles.append({\n",
    "                \"code\": code,\n",
    "                \"title\": f\"Article {num}\",\n",
    "                \"content\": texte,\n",
    "                \"structure\": [\n",
    "                    current_structure[0],\n",
    "                    current_structure[1],\n",
    "                    current_structure[2],\n",
    "                    current_structure[3]\n",
    "                ]\n",
    "            })\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "root=load_code_xml(\"https://codes.droit.org/payloads/Code%20p%C3%A9nal.xml\")\n",
    "new_articles = extract_articles_from_xml(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('dangvantuan/french-document-embedding',trust_remote_code=True)  \n",
    "\n",
    "def embed_articles(all_articles):\n",
    "    texts = [a['content'] for a in all_articles]\n",
    "    embeddings = embedder.encode(texts, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def build_faiss_index(embeddings):\n",
    "    dim = embeddings[0].shape[0]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "    return index\n",
    "\n",
    "\n",
    "def build_graph(all_articles):\n",
    "    G = nx.DiGraph()\n",
    "    for article in all_articles:\n",
    "        G.add_node(article['code']+\" \"+article['title'], content=article['content'])\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec2618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_with_cross_references(G, all_articles):\n",
    "    # Préparer et compiler les patterns\n",
    "    patterns = {\n",
    "        a[\"title\"]: re.compile(\n",
    "            r\"(?<![\\w\\d])\" + re.escape(a[\"title\"]) + r\"(?![\\w\\d])\", \n",
    "            re.IGNORECASE\n",
    "        )\n",
    "        for a in all_articles\n",
    "    }\n",
    "\n",
    "    articles_by_code = {}\n",
    "    for a in all_articles:\n",
    "        articles_by_code.setdefault(a[\"code\"], []).append(a)\n",
    "\n",
    "    # Parcours par code\n",
    "    for code, articles in articles_by_code.items():\n",
    "        for a in tqdm(articles, desc=f\"Cross references for code {code}\"):\n",
    "            source = a[\"title\"]\n",
    "            content = a[\"content\"]\n",
    "\n",
    "            for target_article in articles:\n",
    "                target = target_article[\"title\"]\n",
    "                if target == source:\n",
    "                    continue\n",
    "                if patterns[target].search(content):\n",
    "                    G.add_edge(source, target, relation=\"cite\")\n",
    "\n",
    "def add_structure_nodes(G, all_articles):\n",
    "    for art in all_articles:\n",
    "        if art['structure'] is not None:\n",
    "            structure = re.findall(r\"Livre [IVX]+|Titre [\\w\\s]+|Chapitre [\\w\\d]+\", art['content'])\n",
    "            for node in structure:\n",
    "                if not G.has_node(node):\n",
    "                    G.add_node(node, type=\"structure\")\n",
    "                G.add_edge(node, art['title'], relation=\"contient\")\n",
    "        else:\n",
    "            if not G.has_node(art[\"title\"]):\n",
    "                G.add_node(\n",
    "                    art[\"title\"],\n",
    "                    type=\"article\",\n",
    "                    text=art[\"content\"]\n",
    "                )\n",
    "\n",
    "            # structure nodes\n",
    "            for s in art[\"structure\"]:\n",
    "                if not s:\n",
    "                    continue\n",
    "\n",
    "                if not G.has_node(s):\n",
    "                    G.add_node(s, type=\"structure\")\n",
    "\n",
    "                G.add_edge(s, art[\"title\"], relation=\"contient\")\n",
    "\n",
    "\n",
    "def enrich_with_semantic_similarity(G, all_articles, embeddings, threshold=0.82):\n",
    "    sim_matrix = cosine_similarity(embeddings)\n",
    "    for i in range(len(all_articles)):\n",
    "        for j in range(i+1, len(all_articles)):\n",
    "            if sim_matrix[i][j] >= threshold:\n",
    "                G.add_edge(all_articles[i][\"title\"], all_articles[j][\"title\"], relation=\"similaire\", weight=sim_matrix[i][j])\n",
    "\n",
    "def add_articles_to_graph(G, all_articles):\n",
    "    for art in all_articles:\n",
    "        # article node\n",
    "        if not G.has_node(art[\"title\"]):\n",
    "            G.add_node(\n",
    "                art[\"title\"],\n",
    "                type=\"article\",\n",
    "                text=art[\"content\"]\n",
    "            )\n",
    "\n",
    "        # structure nodes\n",
    "        for s in art[\"structure\"]:\n",
    "            if not s:\n",
    "                continue\n",
    "\n",
    "            if not G.has_node(s):\n",
    "                G.add_node(s, type=\"structure\")\n",
    "\n",
    "            G.add_edge(s, art[\"title\"], relation=\"contient\")\n",
    "\n",
    "def enrich_with_cross_references(G, all_articles):\n",
    "    article_titles = [a[\"title\"] for a in all_articles]\n",
    "\n",
    "    patterns = {\n",
    "        title: re.compile(r\"\\b\" + re.escape(title) + r\"\\b\", re.IGNORECASE)\n",
    "        for title in article_titles\n",
    "    }\n",
    "\n",
    "    for a in tqdm(all_articles, desc=\"Cross references\"):\n",
    "        source = a[\"title\"]\n",
    "        content = a[\"content\"]\n",
    "\n",
    "        for target, pattern in patterns.items():\n",
    "            if target == source:\n",
    "                continue\n",
    "            if pattern.search(content):\n",
    "                G.add_edge(source, target, relation=\"cite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
